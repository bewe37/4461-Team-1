**Section 1:**

The chosen phenomenon of our group is the fabrication of Echo Chambers caused by interactions between bots on centralized social networking apps, with a focus on how bots will abuse the discussions of current real-world events such as natural disasters.   
One of the key dynamics we would like to hone in on is between the users and social media platforms, from the perspective of a user, who expects to use a platform to learn about ongoing situations and news in the world. Instead, users encounter bots who often have alternative objectives when pushing certain posts and messages. These bots often consist of content creators and amplifiers that promote disinformation about specific events, but they can occasionally be looking to share factual information.  
This results in knowledge being skewed, as users on the platform are disinformed and segregated into different groups based on their beliefs. This gives the impression that certain groups on a platform are larger or more influential than they are and creates a large active social media presence for them, ultimately creating an artificial consensus to manipulate public discourse.  
When the social media platform becomes saturated with discussion on topics unrelated to what the user is looking for, or if the discussion involves misinformation, users who disagree with the topics or recognize the inaccuracy or manipulation of information spread by the bots may choose to leave.  
The topic is relevant to today's digital age, as gaining news on social networking apps has become more accessible for users due to news about ongoing events that can be posted by anyone at any time, despite their credentials and source. However, in some cases users fail to recognize the credibility of these posts and the bias that may be held by the poster, resulting in users often becoming disinformed and feeding into the echo chamber by misinforming others. Correspondingly, we want to explore the dynamics in which AI bots congregate together to spread this disinformation and how this butterfly effect impacts a media ecosystem over time.

**Section 2:**

Hajli, N., Saeed, U., Tajvidi, M., & Shirazi, F. (2022). Social Bots and the Spread of Disinformation in Social Media: The Challenges of Artificial Intelligence. *British Journal of Management*, *33*(3), 1238–1253. [https://doi.org/10.1111/1467-8551.12554](https://doi.org/10.1111/1467-8551.12554)

This article looks into the general prevalence of bots on social media in an attempt to determine the intentions of the authors behind them. While the bots sometimes produce positive interactions, in most cases, bots will spread false information, attempt to incite or escalate arguments or sell/create scams. Despite users generally believing the information that bot accounts share less often than human accounts, bots are still commonly able to accelerate the spread of both true and false news, with fake news being the most effective topic to spread.

Hossein Nazer, T. (2019). *Understanding Bots on Social Media – An Application in Disaster Response*. ProQuest Dissertations & Theses.

This dissertation looks into the prevalence of bots on social media during disasters, both malicious and benign, and studies how to identify them, how users interact with them, and the harm that they cause. Hossein defines benign bots as usually being run by a reputable source, that self-identify as bots, and that provides useful information such as weather patterns or disaster alerts. These are in contrast to malicious bots, who often pretend to be human and will share information that tends to be falsified or shared to promote other topics. For example, they may create tweets tagged around both a current disaster and a current political topic, thus creating a connection between the two and drawing attention to their promoted opinion on that political topic. This can cause issues as information that could be vital to disaster response or learning about a current situation will be muddied by unrelated and often extreme political connections. They will also often try to “connect” with many more users than the average human does, spreading their information further.

**Section 3:**

The closest Mesa example to our phenomenon of echo chamber formation in social media is the Schelling Segregation Model, as it illustrates how individuals could become disengaged or segregated from the larger groups when exposed to a large amount of opposing content and misinformation.

**3.1 Entities**

* Human Users  
  * Humans are the primary participants in the social media ecosystem. They actively engage in discussions and continuously communicate and make connections with others.  
  * Roles, Behaviors, and Goals:  
    * They use platforms to gain accurate knowledge of real-world issues and news, which oftentimes can be manipulated by bots.  
    * They tend to interact with others who share the same beliefs or perspectives, sometimes spreading misinformation.  
    * They leave or become disengaged when exposed to a large amount of opposing content, misinformation/disinformation, and conspiracy.  
* Social Bots  
  * Social bots in social media can be categorized into two types; content-creation bots and content-amplifier bots.   
  * Roles, Behaviors, and Goals:  
    * Content-Creation  
      * Content creation bots behave like humans and generate disinformation posts that alter information regarding specific disasters.   
    * Content-Amplifier  
      * Content amplifier bots share specific disinformation content to make it appear dominant.  
        

In connection to the mesa models, generally, the nodes would represent views from human users on a platform. Within these nodes would be squares that represent bots who infiltrate these nodes and cause a shift in the size, as they create and amplify content that shifts the beliefs of human users relating to a disaster or causes them to leave a platform upon realizing the spread of misinformation and disinformation.

**3.2 Affordances**  
Through centralized social media platforms, numerous affordances arise that create action possibilities, potentially impacting data distribution and creating echo chambers. Affordances that content amplifiers would take advantage of include upvoting, liking, and reposting posts. These often appear as little symbols or icons within posts that are easy for users to identify their use and click, such as a heart or up arrow symbol. Content creation bots would use affordances such as hashtags, being adjudicated, and eliciting emotional responses. These affordances are typically in the form of posts which often have keywords to be easily discoverable by users with high associations to the topic and words that could trigger opinions. The goal of using these affordances is to manipulate data to make it appear that these posts are reliable and popular, thus they should be spread to a larger audience to be viewed. Through affordances, bots also appear more trustworthy through their human-like interactions, further influencing users to believe their disinformation. Following the mesa examples, an analogy to represent this would be nodes that represent two views about the reasoning for a disaster, and one of the nodes outgrowing the other due to users believing the view that a bot promotes through the skewing of data from their interactions and affordances.

**3.3 Algorithms**  
Social media platforms rely on various algorithms to drive user engagement. 

* Recommendation Algorithms  
  * Recommendation algorithms analyze the user’s behaviour by tracking their past interactions to prioritize content that is aligned with the user’s preference. This simulates how agents in the Schelling Model prefer similar neighbours.   
    * For example, if a user is exposed to a conspiracy theory post and engages with it, they’ll continue to be exposed to these kinds of posts and continue to possibly be fed disinformation or misinformation.  
  * Content recommendation algorithms could also prioritize AI-generated content, suggesting and reinforcing the visibility of the posts for the AI engagement to pick and interact with. By prioritizing posts created by AI, the system simulates the segregation effect by creating an AI-driven loop and minimizing content created by humans.\`  
* Content Prioritization  
  * The position of posts on social media is related to their engagement rank (likes, shares, and comments). These posts can be driven or created by AI, and as a result, popular content is always placed on the top, and bots could exploit this by amplifying certain narratives, making them appear more dominant. This mirrors how external factors in the Schelling model accelerate segregation by influencing agent movement.

**Section 4:**

![][image1]

Above is a sample output based on the Schelling Segregation Model, roughly representing our goal for the simulation we make based on Schelling

**GREEN nodes** represent humans looking to learn about a disaster  
**PURPLE nodes** represent humans who are further discussing the disaster in connection to unrelated/misinformed factors.  
**RED SQUARED** nodes represent bots.

This could be the result of a platform after a natural disaster has happened. Users are looking to discuss the disaster and learn information about it. In this case, all of the human nodes may have started with values representing small skews in opinion, but generally, all would have been looking to learn about the disaster.  
The step after a disaster happens, the red squared bots would “Activate”, and become more prevalent in the simulation. Green bots represent “benign” bots, which share factual information only. Purple bots represent “malicious” bots, created to connect the disaster with another, likely political, opinion, through disinformation. Over the ensuing steps, many users initially represented by green nodes may change to purple nodes, as they gravitate toward the conspiracies that are being discussed (i.e. when connecting a current disaster with politics). Green users might leave the platform if they think all discussion around them is linked with conspiracy. New users are more likely to start using the platform if they are looking to discuss the same content present, thus they are more likely to be added as an already-purple node. Purple users don’t leave when confronted with green users and bots, as that information does not conflict with their discussions as it does in the other direction. Areas with high concentrations of bots, no matter the kind, are likely to see both kinds of human users leave when around them as they will assume most of the discussion on the platform is being done by bots. To prevent this, bots will auto-sort to maintain distance from each other if they are of the same type, as they are also trying to reach the largest number of human users.  
In an actual simulation of this, it is likely that we will use varying values for, in this case, how “Green” or “Purple” someone is, with their value shifting based on the information they are presented with. There may also be a second variety of “Purple” users which represent another unrelated opinion to the disaster but oppose the purple user's opinion.  


[image1]: <data:image/png;base64,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>